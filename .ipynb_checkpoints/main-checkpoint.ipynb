{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5313739e-ca1c-4682-ac8e-2ad718c8a3ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy version: 2.1.1\n",
      "Pandas version: 2.2.2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(\"Numpy version:\", np.__version__)\n",
    "print(\"Pandas version:\", pd.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60c53187-addc-4d01-8d4b-8511285d8f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5999761a-fee9-41f2-a08c-5a2deb6693d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From ilug-admin@linux.ie Mon Jul 29 11:28:02 2...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From gort44@excite.com Mon Jun 24 17:54:21 200...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From fork-admin@xent.com Mon Jul 29 11:39:57 2...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From dcm123@btamail.net.cn Mon Jun 24 17:49:23...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From ilug-admin@linux.ie Mon Aug 19 11:02:47 2...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  From ilug-admin@linux.ie Mon Jul 29 11:28:02 2...       0\n",
       "1  From gort44@excite.com Mon Jun 24 17:54:21 200...       1\n",
       "2  From fork-admin@xent.com Mon Jul 29 11:39:57 2...       1\n",
       "3  From dcm123@btamail.net.cn Mon Jun 24 17:49:23...       1\n",
       "4  From ilug-admin@linux.ie Mon Aug 19 11:02:47 2...       0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset (replace with your dataset path if required)\n",
    "df = pd.read_csv(r\"C:\\Users\\GF63\\anaconda3\\envs\\textclassificationproject-env\\data\\spam_assassin.csv\")\n",
    "\n",
    "# View the first few rows\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "07c36f32-6606-4d23-8928-68f58e27dc23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\GF63\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.94      1172\n",
      "           1       1.00      0.72      0.84       567\n",
      "\n",
      "    accuracy                           0.91      1739\n",
      "   macro avg       0.94      0.86      0.89      1739\n",
      "weighted avg       0.92      0.91      0.90      1739\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define preprocessing function\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    words = text.split()\n",
    "    words = [stemmer.stem(word) for word in words if word not in stop_words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "# Apply preprocessing to the dataset\n",
    "df['processed_text'] = df['text'].apply(preprocess_text)\n",
    "X = df['processed_text']\n",
    "y = df['target']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Vectorize text data\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_vect = vectorizer.fit_transform(X_train)\n",
    "X_test_vect = vectorizer.transform(X_test)\n",
    "\n",
    "# Train the model\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train_vect, y_train)\n",
    "\n",
    "# Make predictions and evaluate the model\n",
    "y_pred = model.predict(X_test_vect)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d9f22adf-37db-4cb6-9191-cb5811c21bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The email is classified as: Non-Spam\n"
     ]
    }
   ],
   "source": [
    "# Define the function to preprocess and predict\n",
    "def predict_email_category(email_text, model, vectorizer):\n",
    "    # Preprocess the text (cleaning, tokenization, etc.)\n",
    "    processed_text = preprocess_text(email_text)\n",
    "    \n",
    "    # Transform the text to the same feature space as the training data\n",
    "    text_features = vectorizer.transform([processed_text])\n",
    "    \n",
    "    # Predict the category\n",
    "    prediction = model.predict(text_features)\n",
    "    \n",
    "    # Map the prediction to the original labels\n",
    "    if prediction == 0:\n",
    "        return \"Non-Spam\"\n",
    "    else:\n",
    "        return \"Spam\"\n",
    "\n",
    "\n",
    "# Predict the category of the email\n",
    "prediction = predict_email_category(email_text, model, vectorizer)\n",
    "print(f\"The email is classified as: {prediction}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "55892fc7-a3e8-4961-8f7a-9f64778467e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The email is classified as: Non-Spam\n"
     ]
    }
   ],
   "source": [
    "# Define the email content\n",
    "email_text = \"\"\"\n",
    "Dear Danish Akhtar ., \n",
    "\n",
    "Join us for an insightful webinar in collaboration with Datamatics, where we will delve into the latest trends in RPA.\n",
    "\n",
    "Explore advancements in automation, hyper-automation & enhanced capabilities through AI/ML & Natural Language Processing.\n",
    "\n",
    "Gain valuable insights about career opportunities & job market trends in this rapidly evolving field.\n",
    "\n",
    "Don't miss-out on this fantastic opportunity to stay ahead in the world of Robotic Process Automation!\n",
    "\"\"\"\n",
    "\n",
    "# Predict the category of the email\n",
    "prediction = predict_email_category(email_text, model, vectorizer)\n",
    "print(f\"The email is classified as: {prediction}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a20a44-cee3-4b0d-8af3-bf433e2e23e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
